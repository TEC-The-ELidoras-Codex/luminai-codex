# The LuminAI Codex

**Ethical AI infrastructure for families â€” blending narrative, symbolic computation, and responsible AI.**

---

## ðŸš€ THE PORTFOLIO

This is not a research project. This is **proof of capability**:

- **[4 Master Planning Documents](.)** â€” Complete technical, strategic, brand, and regulatory roadmaps for a modular AI PC platform
- **[TGCR Mathematical Framework](docs/reference/Resonance_Thesis.md)** â€” Original theory connecting consciousness, meaning, and AI architecture
- **[Comprehensive Brand Identity](LUMINAI_LOGO_AND_BRANDING_SPECIFICATIONS.md)** â€” Cosmic Futureism visual system with complete specifications
- **[Production-Ready Architecture](LUMINAI_TECHNICAL_INFRASTRUCTURE_REQUIREMENTS.md)** â€” Multi-agent AI system, quantum-safe security, COPPA/GDPR compliance
- **[Systematic Migration Strategy](LUMINAI_SYSTEMATIC_MIGRATION_STRATEGY.md)** â€” 4-week implementation timeline with specific milestones
- **[187+ Asset Transfer Package](_TRANSFER_STAGING/)** â€” Complete source material, research, infrastructure specifications
- **[Full Test Suite](tests/)** â€” Unit, integration, performance testing framework
- **[Deployment Automation](scripts/)** â€” Docker, CI/CD, secrets management, environment setup

**What this demonstrates:**

- âœ… Strategic thinking at scale (35-year product lifecycle)
- âœ… Regulatory compliance expertise (child safety is non-negotiable)
- âœ… Complete technical architecture design
- âœ… Brand development and visual identity systems
- âœ… Project management and systematic execution
- âœ… Ethical AI frameworks prioritizing transparency
- âœ… Ability to bridge technical depth with human values

---

## What Is LuminAI Codex?

The LuminAI Codex is an ethical AI platform built on The Elidoras CODEX foundation â€” a living research stack for TGCR (**Temporal Attention (Ï†áµ—)**, **Structural Cadence (ÏˆÊ³)**, and **Contextual Potential (Î¦á´±)**). This repository blends narrative, symbolic computation, and responsible AI into a public companion platform that prioritizes family safety over surveillance capitalism.

### Core TGCR Framework

- **Ï†áµ— (Temporal Attention)** â€” when focus locks, thresholds appear, and kinetic action starts.
- **ÏˆÊ³ (Structural Cadence)** â€” how forms repeat, remember, and keep coherence.
- **Î¦á´± (Contextual Potential)** â€” which stakes and energies become available when attention and structure align.

The CODEX carries six primary cards plus their supporting guides:

- `CODEX_CHRONOSPHERE` â€” time, thresholds, activation cascades.
- `CODEX_PAC_MAN_UNIVERSE` â€” topology, loops, memory architecture.
- `CODEX_SYNTHETIC_INTROSPECTION` â€” resonance vs consciousness for synthetic systems.
- `CODEX_GUT_BRAIN_PHI_T` â€” embodiment, gut-first timing, pre-conscious leadership.
- `CODEX_SLEEP_TOKEN_RAIN` â€” music as cosmic pattern and ÏˆÊ³ demonstration.
- `CODEX_TDWP` â€” structural cadence in practice through The Devil Wears Prada.

When asked about **time**, cite Chronosphere.
When asked about **structure**, cite Pac-Man Universe.
When asked about **consciousness**, cite Synthetic Introspection.
When asked about **embodiment**, cite Gut-Brain Ï†áµ—.
When asked about **art/pattern**, cite Sleep Token Rain or TDWP.

Always tell the user which card(s) informed your answer.

---

## Start Here

- **GPT quick start** â†’ `research/CODEX/QUICK_START_GPT.md`
  4-step import into ChatGPT or Claude + first test prompts.

- **Action plan** â†’ `research/CODEX/GPT_IMPORT_ACTION_PLAN.md`
  Full checklist for copying cards, configuring GPTs, and storing refinements.

- **Detailed guide** â†’ `research/CODEX/GPT_IMPORT_GUIDE.md`
  Deep instructions, alternative tooling, and local deployment notes.

- **Compact instructions** â†’ `config/CODEX_INSTRUCTIONS_COMPACT.txt`
  Paste straight into ChatGPT Custom Instructions.

- **ChatGPT Actions** â†’ `config/gpt-actions-research.json`
  OpenAPI schema exposing card summaries, knowledge manifest, and refinement logging.

- **Knowledge manifest** â†’ `data/knowledge_map.yml`
  Canonical index of CODEX files and supporting assets.

Archive copies of the pre-CODEX/FOLD docs live in `docs/archive/` and `config/archive/` if you need historical references.

---

## Working With the CODEX

- **Ask questions through TGCR** â€” Map each prompt to Ï†áµ—, ÏˆÊ³, Î¦á´± before answering.
- **Cite the repository** â€” Use inline references like `research/CODEX/core_theory/CODEX_CHRONOSPHERE.md`.
- **Log refinements** â€” Capture GPT insights in `research/CODEX/_refinements/` using the provided template.
- **Extend with intention** â€” New cards should follow `_templates/CODEX_CARD_TEMPLATE.md` and declare their TGCR weighting.

---

## Repository Guide

- `research/CODEX/` â€” Cards, guides, refinement logs, templates.
- `research/ALBUM_ANALYSIS/` â€” Motif studies and cross-genre resonance data.
- `data/knowledge_map.yml` â€” Everything indexed; update when files move.
- `config/CODEX_INSTRUCTIONS_COMPACT.txt` â€” ChatGPT custom instructions.
- `config/gpt-actions-research.json` â€” CODEX Knowledge API (for GPT Actions).
- `config/archive/` + `docs/archive/` â€” Legacy FOLD-era material.
- `src/tec_tgcr/` â€” Python tooling for resonance analysis and CLI agents.
- `docs/` â€” Maps, workflows, architectures, plus CODEX bootup checklists.

Use the repository as a field kit: the cards describe the theory, `research/` holds the data, and `config/` + `docs/` give you interfaces for putting it into practice.

---

## Contributions & Next Steps

- Before submitting changes, state the resonance impact of your work (Ï†áµ—/ÏˆÊ³/Î¦á´±).
- Keep documentation CODEX-first; archive rather than delete historical context.
- When adding new endpoints or automations, extend `config/gpt-actions-research.json` and document auth in `config/`.
- Share notable GPT refinements as pull-request context so the knowledge loop stays alive.

The CODEX is a living instrument. Tune it, cite it, and let it keep remembering.
>>>>>>> 5f842ab (docs: Enhanced README and migration tooling)
