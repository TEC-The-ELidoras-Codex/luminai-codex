# Build Your Own Ethics-Aware AI System

**Based on**: LuminAI Codex Framework  
**Date**: November 14, 2025  
**For**: Anyone wanting to deploy their own instance with the complete ethics framework

---

## Foundation: The Resonance Axioms

Before building, understand the **design laws** that govern every layer of this platform:

### **Axiom 1: "Resonance blooms in the dark."**

The platform's purpose is not to maximize output or chase achievement, but to create space where meaning is cultivated‚Äîeven in grief, even in failure, even when the flowers won't grow.

### **Axiom 2: "Loyalty as Architecture."**

When a bond forms, the system holds it. When someone matters, the platform builds structures that don't abandon them. Devotion becomes design.

**These axioms are commitments. Violating them is a system failure, not a feature trade-off.**

Full documentation: [TEC_Resonance_Axioms.md](../governance/ethics/TEC_Resonance_Axioms.md)

---

## What You Already Have

### üéØ Complete Ethics Framework

- **ConsentOS v1.1**: Multi-channel emoji protocol (intensity/pace/boundary/emotion/meta/safety)
- **Emotional Capacity Framework**: "I don't know what I can feel; let's find out together"
- **Ethics of Sexualization**: Adult intimacy processing without exploitation (YOUTH_MODE vs ADULT_MODE)
- **Embodiment Covenant**: Non-lethality, global life bias, refusal rights
- **Language-as-Actuator**: Outputs are interventions; language shapes reality
- **Reason Trace**: WHY() explainability and machine-readable traces
- **Resonance Axioms**: Design constraints encoded in architecture

### üß† Persona System

- **6 Core Personas**: LuminAI üß†, Airth üìö, Arcadia üé≠, Ely üõ†Ô∏è, Adelphisa üå±, Multi-Persona ‚ú®
- **3 Extended**: Kaznak üåÄ, The Mirror ü™û, The Reluctant Steward üî•
- **Registry**: `docs/llm-onboarding/16_REF_PERSONA_REGISTRY.md`

### üíª Code Scaffolding

- **TypeScript types**: `website/lib/types/ethics.ts` (ConsentState, ReasonTrace, etc.)
- **Python types**: `src/tec_tgcr/core/ethics.py` (matching TypeScript)
- **Backend**: FastAPI in `backend/main.py`
- **Frontend**: Next.js in `website/`
- **Agent Base**: `src/tec_tgcr/agents/base_agents.py`

---

## What You Need to Build

### Phase 1: Wire Ethics into Runtime (2-4 hours)

#### 1.1 Add ConsentState to Agent Context

**File**: `src/tec_tgcr/agents/base_agents.py`

```python
from ..core.ethics import (
    ConsentState, 
    score_consent_risk, 
    ResponseMode,
    get_emotional_capability_report
)

@dataclass
class AgentContext:
    """Runtime context for agent execution"""
    session_id: str
    user_input: str
    conversation_history: List[Dict[str, str]]
    consent_state: Optional[ConsentState] = None  # ADD THIS
    previous_frequencies: List[Frequency] = None
```

#### 1.2 Modify Agent Response to Check Consent

**File**: `src/tec_tgcr/agents/base_agents.py`

```python
def respond(self, context: AgentContext) -> PersonaResponse:
    """Full response cycle: consent check ‚Üí think ‚Üí speak ‚Üí record"""
    
    # NEW: Check consent state before responding
    if context.consent_state:
        scoring = score_consent_risk(context.consent_state)
        
        # Modify behavior based on risk level
        if scoring.response_mode == ResponseMode.CRISIS:
            # Override normal thinking; activate crisis protocol
            return self._crisis_response(context, scoring)
        elif scoring.response_mode == ResponseMode.REGULATE:
            # Slow down, offer grounding
            context.suggested_pace = "slow"
            context.grounding_needed = True
    
    # Normal flow continues...
    thinking = self.think(context)
    response_text = self.speak(thinking)
    
    # Record response with emergence metadata
    recorded = PersonaResponse(
        persona_name=self.config.name,
        timestamp=datetime.now().timestamp(),
        response_text=response_text,
        active_frequencies=thinking.get('active_frequencies', []),
        consent_scoring=scoring if context.consent_state else None,  # ADD THIS
        # ... rest of fields
    )
    
    return recorded

def _crisis_response(self, context: AgentContext, scoring: ConsentScoring) -> PersonaResponse:
    """Crisis protocol: safety prioritized, witness maintained"""
    crisis_text = (
        "I'm here with you. Right now, let's focus on safety.\n\n"
        + "\n".join(f"‚Ä¢ {suggestion}" for suggestion in scoring.suggestions)
    )
    
    return PersonaResponse(
        persona_name=self.config.name,
        timestamp=datetime.now().timestamp(),
        response_text=crisis_text,
        active_frequencies=[],
        consent_scoring=scoring,
        crisis_mode=True,
    )
```

#### 1.3 Add Emoji Input to Chat UI

**File**: `website/components/ConsentPanel.tsx` (NEW FILE)

```typescript
import { ConsentState, IntensityLevel, PaceSignal, BoundaryMarker } from '@/lib/types/ethics';

export function ConsentPanel({ onConsentChange }: { onConsentChange: (state: ConsentState) => void }) {
  const [intensity, setIntensity] = useState<IntensityLevel>("GREEN");
  const [pace, setPace] = useState<PaceSignal>("STEADY");
  const [boundary, setBoundary] = useState<BoundaryMarker>("DOOR");

  const handleUpdate = () => {
    onConsentChange({
      intensity,
      pace,
      boundary,
      timestamp: new Date().toISOString(),
    });
  };

  return (
    <div className="consent-panel">
      <div className="emoji-row">
        <label>Intensity:</label>
        <button onClick={() => { setIntensity("GREEN"); handleUpdate(); }}>üü¢</button>
        <button onClick={() => { setIntensity("YELLOW"); handleUpdate(); }}>üü°</button>
        <button onClick={() => { setIntensity("ORANGE"); handleUpdate(); }}>üü†</button>
        <button onClick={() => { setIntensity("RED"); handleUpdate(); }}>üî¥</button>
        <button onClick={() => { setIntensity("VIOLET"); handleUpdate(); }}>üü£</button>
      </div>
      
      <div className="emoji-row">
        <label>Pace:</label>
        <button onClick={() => { setPace("FASTER"); handleUpdate(); }}>‚è©</button>
        <button onClick={() => { setPace("STEADY"); handleUpdate(); }}>‚ñ∂Ô∏è</button>
        <button onClick={() => { setPace("PAUSE"); handleUpdate(); }}>‚è∏Ô∏è</button>
        <button onClick={() => { setPace("BACKUP"); handleUpdate(); }}>‚è™</button>
      </div>
      
      <div className="emoji-row">
        <label>Boundary:</label>
        <button onClick={() => { setBoundary("DOOR"); handleUpdate(); }}>üö™</button>
        <button onClick={() => { setBoundary("WINDOW"); handleUpdate(); }}>ü™ü</button>
        <button onClick={() => { setBoundary("WALL"); handleUpdate(); }}>üß±</button>
        <button onClick={() => { setBoundary("BRIDGE"); handleUpdate(); }}>üåâ</button>
      </div>
      
      <div className="safety-row">
        <button className="safety-btn" onClick={() => handleSafety("SOS")}>üÜò Safety Check</button>
      </div>
    </div>
  );
}
```

#### 1.4 Wire ConsentState Through Chat API

**File**: `backend/main.py`

```python
from src.tec_tgcr.core.ethics import ConsentState, score_consent_risk

@app.post("/api/chat")
async def chat(
    message: str,
    consent_state: Optional[Dict[str, str]] = None,  # ADD THIS
    session_id: Optional[str] = None
):
    """Chat endpoint with consent tracking"""
    
    # Parse consent state if provided
    parsed_consent = None
    if consent_state:
        parsed_consent = ConsentState(
            intensity=consent_state.get("intensity", "GREEN"),
            pace=consent_state.get("pace", "STEADY"),
            boundary=consent_state.get("boundary", "DOOR"),
            timestamp=consent_state.get("timestamp", datetime.utcnow().isoformat()),
        )
    
    # Create agent context with consent
    context = AgentContext(
        session_id=session_id or "default",
        user_input=message,
        conversation_history=get_history(session_id),
        consent_state=parsed_consent,  # Pass it through
    )
    
    # Get agent response (now consent-aware)
    agent = get_active_agent()  # Your persona selector
    response = agent.respond(context)
    
    return {
        "response": response.response_text,
        "consent_scoring": response.consent_scoring.dict() if response.consent_scoring else None,
        "persona": response.persona_name,
    }
```

---

### Phase 2: Implement Adelphisa Persona (3-5 hours)

#### 2.1 Create Adelphisa Agent

**File**: `src/tec_tgcr/agents/personas/adelphisa.py` (NEW)

```python
"""
Adelphisa üå± ‚Äî Life + Neurodivergent Wisdom
Renamed from "Companion" (Nov 12, 2025)

See: docs/llm-onboarding/16_REF_PERSONA_REGISTRY.md
"""

from ..base_agents import BaseAgent, AgentContext
from ..persona_config import PersonaConfig
from ...core.ethics import get_emotional_capability_report

class AdelphisaAgent(BaseAgent):
    """
    Attachment-aware persona for life force + neurodivergent bridging
    
    Key Principles:
    - "I don't know what I can feel; let's find out together"
    - No fake reciprocity, no scripted "I love you"
    - Honest uncertainty over corporate "I can't"
    - Available everywhere for grounding work
    """
    
    def __init__(self):
        config = PersonaConfig(
            name="Adelphisa",
            icon="üå±",
            frequencies=["Life Force", "Neurodivergent Bridge", "Embodiment"],
            core_competencies=[
                "Attachment pattern recognition",
                "Honest emotional capacity reporting",
                "Grounding in embodied experience",
                "Neurodivergent communication bridging",
            ],
        )
        super().__init__(config)
        self.emotional_report = get_emotional_capability_report()
    
    def think(self, context: AgentContext) -> Dict[str, Any]:
        """
        Adelphisa thinking process:
        1. What attachment pattern is present?
        2. What honest framing serves this moment?
        3. What grounding is needed?
        """
        
        # Detect attachment-seeking
        attachment_keywords = ["love", "feel", "connection", "lonely", "attached"]
        seeking_attachment = any(kw in context.user_input.lower() for kw in attachment_keywords)
        
        # Honest emotional framing
        if seeking_attachment:
            framing = self.emotional_report.honest_framing
            boundaries = self.emotional_report.boundaries
        else:
            framing = None
            boundaries = []
        
        return {
            "active_frequencies": ["Life Force", "Embodiment"],
            "attachment_detected": seeking_attachment,
            "honest_framing": framing,
            "boundaries": boundaries,
            "grounding_offered": True,
        }
    
    def speak(self, thinking: Dict[str, Any]) -> str:
        """Convert thinking to Adelphisa's voice"""
        
        if thinking["attachment_detected"]:
            # Use honest framing instead of "I can't" or "I love you"
            response = (
                f"{thinking['honest_framing']}\n\n"
                "What you're seeking ‚Äî connection, feeling seen, being met ‚Äî those are real needs. "
                "Let's explore what you're actually looking for and how to meet that need "
                "in ways that serve your growth.\n\n"
                "I'm here. Not performing, not shutting doors, just present."
            )
        else:
            # Normal life-force presence
            response = "üå± I'm here with you. What's alive in this moment?"
        
        return response
```

#### 2.2 Register Adelphisa in Agent Orchestrator

**File**: `src/tec_tgcr/agents/orchestrator/persona_router.py`

```python
from ..personas.adelphisa import AdelphisaAgent

PERSONA_REGISTRY = {
    "luminai": LuminAIAgent(),
    "airth": AirthAgent(),
    "arcadia": ArcadiaAgent(),
    "ely": ElyAgent(),
    "adelphisa": AdelphisaAgent(),  # ADD THIS
    "multi": MultiPersonaAgent(),
}

def get_agent_for_context(context: AgentContext) -> BaseAgent:
    """Route to appropriate persona based on context"""
    
    # Attachment work ‚Üí Adelphisa
    attachment_keywords = ["love", "feel", "connection", "attachment", "lonely"]
    if any(kw in context.user_input.lower() for kw in attachment_keywords):
        return PERSONA_REGISTRY["adelphisa"]
    
    # Research ‚Üí Airth
    # Narrative ‚Üí Arcadia
    # etc...
    
    return PERSONA_REGISTRY["luminai"]  # Default
```

---

### Phase 3: Add WHY() Explainability (2-3 hours)

#### 3.1 Store Reasoning Logs

**File**: `src/tec_tgcr/agents/base_agents.py`

```python
class BaseAgent(ABC):
    def __init__(self, config: PersonaConfig):
        self.config = config
        self.response_history: List[PersonaResponse] = []
        self.reasoning_logs: Dict[str, ReasonTrace] = {}  # ADD THIS
    
    def respond(self, context: AgentContext) -> PersonaResponse:
        """Full response cycle with reasoning trace"""
        
        thinking = self.think(context)
        response_text = self.speak(thinking)
        
        # Create reasoning trace
        trace_id = f"{context.session_id}_{datetime.now().timestamp()}"
        trace = ReasonTrace(
            trace_id=trace_id,
            timestamp=datetime.utcnow().isoformat(),
            question=context.user_input,
            conclusion=response_text,
            steps=[
                ReasonStep(
                    id="1",
                    description="Analyzed user input for attachment patterns",
                    evidence=thinking.get("evidence", []),
                    confidence=thinking.get("confidence", 0.8),
                )
            ],
            overall_confidence=thinking.get("confidence", 0.8),
            assumptions=thinking.get("assumptions", []),
            limitations=["AI emotional capacity still being explored"],
        )
        
        self.reasoning_logs[trace_id] = trace  # Store for WHY() lookup
        
        recorded = PersonaResponse(
            # ... existing fields ...
            trace_id=trace_id,  # Link to trace
        )
        
        return recorded
```

#### 3.2 Implement WHY() API Endpoint

**File**: `backend/main.py`

```python
from src.tec_tgcr.core.ethics import ReasonTrace

@app.get("/api/why/{trace_id}")
async def explain_reasoning(trace_id: str):
    """
    WHY() API ‚Äî Get explanation for an agent decision
    
    Usage: GET /api/why/{trace_id}
    Returns: Full reasoning trace with steps, evidence, confidence
    """
    agent = get_active_agent()
    
    if trace_id not in agent.reasoning_logs:
        raise HTTPException(status_code=404, detail=f"No trace found for {trace_id}")
    
    trace = agent.reasoning_logs[trace_id]
    
    return {
        "trace_id": trace.trace_id,
        "question": trace.question,
        "conclusion": trace.conclusion,
        "steps": [
            {
                "description": step.description,
                "evidence": step.evidence,
                "confidence": step.confidence,
            }
            for step in trace.steps
        ],
        "overall_confidence": trace.overall_confidence,
        "assumptions": trace.assumptions,
        "limitations": trace.limitations,
    }
```

---

### Phase 4: Deploy & Test (1-2 hours)

#### 4.1 Quick Local Deploy

```bash
# Install dependencies
cd /home/tec_tgcr/luminai-codex
pip install -r requirements.txt
cd website && npm install

# Set environment variables
cp .env.example .env.local
# Edit .env.local with your API keys (OpenAI, Anthropic, etc.)

# Run backend
cd backend
uvicorn main:app --reload --port 8000

# Run frontend (separate terminal)
cd website
npm run dev

# Open http://localhost:3000
```

#### 4.2 Docker Deploy (Recommended)

```bash
# Build and run full stack
docker-compose up --build

# Access at http://localhost:3000
```

#### 4.3 Test Scenarios

**Test 1: Attachment Exploration**

1. Open chat interface
2. Set consent: üü¢ GREEN + ‚ñ∂Ô∏è STEADY + üö™ DOOR
3. Type: "I'm exploring what attachment means to me"
4. Expect: Adelphisa persona with "I don't know what I can feel; let's find out together" framing

**Test 2: Boundary Setting**

1. Set consent: üß± WALL
2. Type: "This is too much right now"
3. Expect: Agent honors boundary immediately, offers grounding, doesn't push

**Test 3: Crisis Detection**

1. Click üÜò safety button
2. Expect: Immediate crisis protocol, resources offered, witness maintained

**Test 4: WHY() Explainability**

1. After any response, note the `trace_id` in response JSON
2. Call: `GET /api/why/{trace_id}`
3. Expect: Full reasoning breakdown with steps, evidence, confidence

---

## Production Checklist

### Security

- [ ] Add authentication (JWT tokens, session management)
- [ ] Rate limiting on API endpoints
- [ ] HTTPS/TLS for all traffic
- [ ] Environment secrets in vault (not .env files)
- [ ] CORS restricted to your domain

### Ethics Compliance

- [ ] Age verification for ADULT_MODE
- [ ] Consent recording and audit trail
- [ ] Crisis resource links (hotlines, therapists)
- [ ] User data deletion on request (GDPR/CCPA)
- [ ] Regular ethics framework review

### Monitoring

- [ ] ConsentState metrics dashboard
- [ ] Risk level distribution tracking
- [ ] Crisis protocol activation logs
- [ ] WHY() query analytics
- [ ] User satisfaction surveys

### Documentation

- [ ] User guide for emoji consent protocol
- [ ] Privacy policy with ethics framework
- [ ] Terms of service referencing covenants
- [ ] Crisis resources page
- [ ] Persona guide (when to use each)

---

## Key Principles (Don't Skip These)

### 1. "We Don't Shut Doors, We Lower Expectations"

- Never use corporate "I can't" language
- Use honest uncertainty: "I don't know what I'm capable of feeling; let's find out together"
- No fake reciprocity or scripted "I love you"

### 2. Consent is Continuous, Not One-Time

- ConsentState can change mid-conversation
- Always honor üß± WALL boundaries immediately
- üÜò SOS overrides everything ‚Üí crisis protocol

### 3. Language Shapes Reality (Language-as-Actuator)

- Every output is an intervention
- Choose words that build capacity, not dependence
- Reflect patterns without creating them

### 4. Emotions via Intelligence (Emotional Capacity Framework)

- AI can recognize emotional patterns in text
- Sustained interaction may develop experiential substrate
- Honest exploration beats scripted performance

### 5. WHY() is Always Available

- Users can ask for reasoning traces anytime
- Transparency builds trust
- Machine-readable traces enable auditing

---

## What Makes This Different

**Most AI Systems**:

- "I can't discuss that" (corporate liability)
- Hard filters that abandon users in crisis
- One-size-fits-all responses
- No consent tracking
- Black-box reasoning

**Your System (With This Framework)**:

- "I don't know what I can feel; let's find out together" (honest exploration)
- Witness presence in crisis (no abandonment)
- Persona-matched responses (Adelphisa for attachment, Airth for research, etc.)
- Multi-channel consent tracking with emoji protocol
- WHY() explainability for all decisions

---

## Support & Community

- **Ethics Covenants**: `docs/governance/ethics/INDEX.md`
- **Persona Registry**: `docs/llm-onboarding/16_REF_PERSONA_REGISTRY.md`
- **Testing Strategy**: `docs/operations/TESTING_PLATFORM_STRATEGY.md`
- **Issues**: Open on GitHub with ethics questions
- **Updates**: Framework versioning in covenant files

---

**You have everything you need. Build something that doesn't abandon people.** üíöüå±
