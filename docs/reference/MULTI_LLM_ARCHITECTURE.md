# Multi-LLM Collaboration System Architecture

## System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     LUMINAI RESONANCE PLATFORM                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                  FRONTEND (React 18 + TS)               â”‚   â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
â”‚  â”‚                                                           â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚  â”‚  LLM Sel    â”‚  â”‚  Collaboration   â”‚  â”‚ Resonance  â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  Provider   â”‚  â”‚  Panel           â”‚  â”‚ Map        â”‚  â”‚   â”‚
â”‚  â”‚  â”‚             â”‚  â”‚                  â”‚  â”‚            â”‚  â”‚   â”‚
â”‚  â”‚  â”‚ â€¢ OpenAI    â”‚  â”‚ â€¢ Users (4-8)    â”‚  â”‚ â€¢ Concepts â”‚  â”‚   â”‚
â”‚  â”‚  â”‚ â€¢ Anthropic â”‚  â”‚ â€¢ Recording      â”‚  â”‚ â€¢ Orbits   â”‚  â”‚   â”‚
â”‚  â”‚  â”‚ â€¢ xAI       â”‚  â”‚ â€¢ Resonance â˜   â”‚  â”‚ â€¢ Physics  â”‚  â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â”‚                                                           â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚  â”‚           MultiLLMChat Component                   â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚  â”‚   â”‚
â”‚  â”‚  â”‚                                                    â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  User: "Explain consciousness"                    â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  â””â”€ [user message - blue]                         â”‚  â”‚   â”‚
â”‚  â”‚  â”‚                                                    â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  Claude ðŸŸ : "It involves..." (âš™ï¸ thinking)        â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  â””â”€ [Claude response - orange gradient]           â”‚  â”‚   â”‚
â”‚  â”‚  â”‚                                                    â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  GPT-4 ðŸ”µ: "Building on Claude..." (âš™ï¸ thinking)  â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  â””â”€ [GPT-4 response - blue gradient]              â”‚  â”‚   â”‚
â”‚  â”‚  â”‚                                                    â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  Grok âœ¨: "However, both missed..." (âš™ï¸ thinking) â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  â””â”€ [Grok response - purple gradient]             â”‚  â”‚   â”‚
â”‚  â”‚  â”‚                                                    â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  [?] Help  [â†“] Export  [ðŸ’¾] Save                  â”‚  â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â”‚                                                           â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â†“                                   â”‚
â”‚                    HTTP/REST API Calls                          â”‚
â”‚                              â†“                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                  BACKEND (FastAPI + Python)              â”‚   â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
â”‚  â”‚                                                           â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚
â”‚  â”‚  â”‚  /api/multi-llm/response                         â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  POST {persona, context, systemPrompt}           â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€       â”‚   â”‚   â”‚
â”‚  â”‚  â”‚                                                  â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  1. Get API key from environment                â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  2. Format message context                      â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  3. Instantiate provider                        â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  4. Call LLM API                                â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  5. Return response                             â”‚   â”‚   â”‚
â”‚  â”‚  â”‚                                                  â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  return {response, model, tokensUsed}           â”‚   â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚
â”‚  â”‚                                                           â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚   â”‚
â”‚  â”‚  â”‚ Claude   â”‚  â”‚ GPT-4    â”‚  â”‚ Grok   â”‚                â”‚   â”‚
â”‚  â”‚  â”‚ Provider â”‚  â”‚ Provider â”‚  â”‚Provide â”‚                â”‚   â”‚
â”‚  â”‚  â”‚          â”‚  â”‚          â”‚  â”‚        â”‚                â”‚   â”‚
â”‚  â”‚  â”‚Anthropic â”‚  â”‚ OpenAI   â”‚  â”‚  xAI   â”‚                â”‚   â”‚
â”‚  â”‚  â”‚Claude-3  â”‚  â”‚GPT-4     â”‚  â”‚Grok-1  â”‚                â”‚   â”‚
â”‚  â”‚  â”‚Opus      â”‚  â”‚Turbo     â”‚  â”‚        â”‚                â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚   â”‚
â”‚  â”‚        â†“              â†“             â†“                   â”‚   â”‚
â”‚  â”‚     (API Call)    (API Call)    (API Call)             â”‚   â”‚
â”‚  â”‚                                                           â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚         â†“              â†“              â†“                         â”‚
â”‚    (HTTPS)         (HTTPS)        (HTTPS)                      â”‚
â”‚         â†“              â†“              â†“                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚ Anthropic    â”‚ â”‚ OpenAI  â”‚ â”‚ xAI              â”‚            â”‚
â”‚  â”‚ API          â”‚ â”‚ API     â”‚ â”‚ API              â”‚            â”‚
â”‚  â”‚              â”‚ â”‚         â”‚ â”‚                  â”‚            â”‚
â”‚  â”‚claude-3-opus â”‚ â”‚gpt-4    â”‚ â”‚grok-1            â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Message Flow Sequence

### Single Turn: User â†’ 3 LLMs â†’ Responses

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    User Sends Message                    â”‚
â”‚                  "Explain consciousness"                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ MultiLLMChat.handleSendMessage()   â”‚
         â”‚  â€¢ Add message to UI (blue)        â”‚
         â”‚  â€¢ Set isProcessing = true         â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚         â”‚         â”‚
                â–¼         â”‚         â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚         â”‚
         â”‚  Claude ðŸŸ    â”‚ â”‚         â”‚
         â”‚   (Step 1)   â”‚ â”‚         â”‚
         â”‚              â”‚ â”‚         â”‚
         â”‚ POST /api/   â”‚ â”‚         â”‚
         â”‚ multi-llm/   â”‚ â”‚         â”‚
         â”‚ response     â”‚ â”‚         â”‚
         â”‚ {persona:    â”‚ â”‚         â”‚
         â”‚  'claude',   â”‚ â”‚         â”‚
         â”‚  context: [  â”‚ â”‚         â”‚
         â”‚    {user msg}â”‚ â”‚         â”‚
         â”‚  ]}          â”‚ â”‚         â”‚
         â”‚              â”‚ â”‚         â”‚
         â”‚ â†“ Response   â”‚ â”‚         â”‚
         â”‚ "It involves â”‚ â”‚         â”‚
         â”‚  awareness"  â”‚ â”‚         â”‚
         â”‚              â”‚ â”‚         â”‚
         â”‚ Add to UI    â”‚ â”‚         â”‚
         â”‚ (orange)     â”‚ â”‚         â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚         â”‚
                          â”‚         â”‚
                          â–¼         â”‚
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                 â”‚  GPT-4 ðŸ”µ        â”‚
                 â”‚  (Step 2)        â”‚
                 â”‚                  â”‚
                 â”‚ POST /api/       â”‚
                 â”‚ multi-llm/       â”‚
                 â”‚ response         â”‚
                 â”‚ {persona:        â”‚
                 â”‚  'openai',       â”‚
                 â”‚  context: [      â”‚
                 â”‚   {user msg},    â”‚
                 â”‚   [Claude]:      â”‚
                 â”‚    "response"    â”‚
                 â”‚  ]}              â”‚
                 â”‚                  â”‚
                 â”‚ â†“ Response       â”‚
                 â”‚ "Building on     â”‚
                 â”‚  Claude..."      â”‚
                 â”‚                  â”‚
                 â”‚ Add to UI        â”‚
                 â”‚ (blue)           â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                                    â”‚
                                    â–¼
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚  Grok âœ¨         â”‚
                         â”‚  (Step 3)        â”‚
                         â”‚                  â”‚
                         â”‚ POST /api/       â”‚
                         â”‚ multi-llm/       â”‚
                         â”‚ response         â”‚
                         â”‚ {persona:        â”‚
                         â”‚  'xai',          â”‚
                         â”‚  context: [      â”‚
                         â”‚   {user msg},    â”‚
                         â”‚   [Claude]:      â”‚
                         â”‚    "response",   â”‚
                         â”‚   [GPT-4]:       â”‚
                         â”‚    "response"    â”‚
                         â”‚  ]}              â”‚
                         â”‚                  â”‚
                         â”‚ â†“ Response       â”‚
                         â”‚ "However,        â”‚
                         â”‚  both missed..." â”‚
                         â”‚                  â”‚
                         â”‚ Add to UI        â”‚
                         â”‚ (purple)         â”‚
                         â”‚                  â”‚
                         â”‚ Set processing   â”‚
                         â”‚ = false          â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Component Hierarchy

```
ChatPage (Layout)
â”‚
â”œâ”€â”€ Header
â”‚   â”œâ”€â”€ Title: "LuminAI Resonance"
â”‚   â””â”€â”€ LLMProviderSelector (inline mode)
â”‚
â”œâ”€â”€ Left Sidebar (col-span-1)
â”‚   â”œâ”€â”€ CollaborationPanel
â”‚   â”‚   â”œâ”€â”€ Session Info
â”‚   â”‚   â”œâ”€â”€ User Avatars
â”‚   â”‚   â”œâ”€â”€ Recording Toggle
â”‚   â”‚   â”œâ”€â”€ Resonance Score
â”‚   â”‚   â””â”€â”€ Invite Controls
â”‚   â”‚
â”‚   â”œâ”€â”€ CompactResonanceMap
â”‚   â”‚   â”œâ”€â”€ Canvas (orbiting concepts)
â”‚   â”‚   â”œâ”€â”€ Interaction Handlers
â”‚   â”‚   â””â”€â”€ Legend
â”‚   â”‚
â”‚   â””â”€â”€ Quick Stats
â”‚       â”œâ”€â”€ Concept Count
â”‚       â”œâ”€â”€ Connection Count
â”‚       â””â”€â”€ Message Count
â”‚
â””â”€â”€ Main Content (col-span-3)
    â””â”€â”€ MultiLLMChat
        â”œâ”€â”€ Header
        â”‚   â”œâ”€â”€ Help Icon (?)
        â”‚   â””â”€â”€ Menu [Export, etc.]
        â”‚
        â”œâ”€â”€ Messages Container
        â”‚   â”œâ”€â”€ User Message (blue gradient)
        â”‚   â”œâ”€â”€ Claude ðŸŸ  Message (orange gradient)
        â”‚   â”‚   â””â”€â”€ Thinking Animation
        â”‚   â”œâ”€â”€ GPT-4 ðŸ”µ Message (blue gradient)
        â”‚   â”‚   â””â”€â”€ Thinking Animation
        â”‚   â””â”€â”€ Grok âœ¨ Message (purple gradient)
        â”‚       â””â”€â”€ Thinking Animation
        â”‚
        â”œâ”€â”€ Input Area
        â”‚   â”œâ”€â”€ Text Input
        â”‚   â”œâ”€â”€ Send Button
        â”‚   â””â”€â”€ Upload Button (optional)
        â”‚
        â””â”€â”€ Footer
            â””â”€â”€ Status: "Ready" | "Processing..."
```

## State Management

### Frontend Component State

```typescript
// Chat Page Level
{
  selectedLLM: 'openai' | 'anthropic' | 'xai' | null
  selectedModel: 'gpt-4-turbo' | 'claude-3-opus' | 'grok-1' | null
  conversationId: string
  concepts: Concept[]  // From resonance map
  connections: Resonance[]  // Concept connections
}

// MultiLLMChat Component
{
  messages: Message[]  // All messages in conversation
  isProcessing: boolean  // Currently fetching LLM responses
  hoveredNode: string | null  // For resonance map hover
}

// CollaborationPanel Component
{
  currentUsers: CollaborativeUser[]
  isRecording: boolean
  resonanceScore: number
  showInviteForm: boolean
}

// CompactResonanceMap Component
{
  selectedConcept: string | null
  animating: boolean
}
```

## API Contract

### POST /api/multi-llm/response

**Request:**
```json
{
  "persona": "claude" | "openai" | "xai",
  "conversationId": "string",
  "context": [
    {
      "role": "user" | "assistant",
      "content": "string",
      "persona": "claude" | "openai" | "xai" | "user"
    }
  ],
  "systemPrompt": "string"
}
```

**Response:**
```json
{
  "response": "string",
  "persona": "claude" | "openai" | "xai",
  "model": "claude-3-opus" | "gpt-4-turbo-preview" | "grok-1",
  "tokensUsed": 42
}
```

### GET /api/multi-llm/personas

**Response:**
```json
{
  "claude": {
    "name": "Claude",
    "icon": "ðŸŸ ",
    "models": ["claude-3-opus", "claude-3-sonnet"],
    "strengths": ["reasoning", "nuance", "ethics"],
    "color": "orange",
    "specialty": "Deep thinking"
  },
  "openai": {
    "name": "GPT-4",
    "icon": "ðŸ”µ",
    "models": ["gpt-4-turbo-preview", "gpt-4"],
    "strengths": ["creativity", "practicality"],
    "color": "blue",
    "specialty": "Creative implementation"
  },
  "xai": {
    "name": "Grok",
    "icon": "âœ¨",
    "models": ["grok-1"],
    "strengths": ["directness", "critique"],
    "color": "purple",
    "specialty": "Critical analysis"
  }
}
```

## Data Flow

### Message Processing Pipeline

1. **User Input** â†’ Text in MultiLLMChat input
2. **Send Trigger** â†’ `handleSendMessage()` called
3. **UI Update** â†’ User message added (blue card)
4. **Processing** â†’ `isProcessing = true`, show spinner
5. **API Call #1** â†’ Claude persona, full context
6. **Response 1** â†’ Claude response received, added to UI
7. **API Call #2** â†’ OpenAI persona, context + Claude response
8. **Response 2** â†’ GPT-4 response received, added to UI
9. **API Call #3** â†’ xAI persona, context + both previous responses
10. **Response 3** â†’ Grok response received, added to UI
11. **Cleanup** â†’ `isProcessing = false`, disable spinner
12. **Resonance** â†’ Update concept map, recalculate score

### Concept Extraction

```
Message Text
    â†“
[NLP Processing]
    â†“
Extract Keywords (length > 4)
    â†“
Group by Frequency
    â†“
Calculate Connections
    â†“
Update CompactResonanceMap
    â†“
Animate Orbiting Nodes
```

## Resonance Calculation

```
For each LLM response:
  - Parse sentiment/confidence
  - Calculate coherence with previous responses
  - Extract key insights

Group Score = (Î£ individual scores) / 3

Components:
  - agreement (0-1): How well responses align
  - coherence (0-1): Logical consistency
  - insight_depth (0-1): Quality of analysis

R = (agreement Ã— coherence Ã— insight_depth) / 3
```

## Error Handling

### Missing API Keys
- Backend checks `ANTHROPIC_API_KEY`, `OPENAI_API_KEY`, `XAI_API_KEY`
- Returns demo response if key missing
- Logs warning but continues

### API Rate Limits
- Implement exponential backoff
- Queue requests if rate limited
- Show user "API limit reached" message

### Network Timeouts
- Default timeout: 30 seconds
- Show "Still thinking..." after 10 seconds
- Allow cancel operation
- Retry with exponential backoff

### Invalid Requests
- Validate schema on backend
- Return 400 Bad Request
- Log issue for debugging

## Performance Considerations

1. **Sequential Processing** (Current)
   - Claude responds first (1-3s)
   - GPT-4 responds second (1-3s)
   - Grok responds third (1-3s)
   - Total: ~3-9 seconds per turn

2. **Optimization Opportunities**
   - Parallelize Claude + GPT-4 (they only use user message)
   - Use cheaper models for context building
   - Implement response caching
   - Batch similar requests

3. **Token Management**
   - Track tokens per provider
   - Warn if approaching budget
   - Suggest model downgrade if needed

## Security Considerations

1. **API Keys**
   - Never log keys
   - Use environment variables
   - Rotate regularly

2. **Rate Limiting**
   - Per-user rate limits
   - Per-IP rate limits
   - Global service limits

3. **Data Privacy**
   - Encrypt conversations in database
   - Don't share prompts across users
   - Implement user authentication

4. **Prompt Injection**
   - Sanitize user input
   - Validate system prompts
   - Use parameterized requests

## Future Enhancements

1. **Real-time WebSocket**
   - Live multi-user sync
   - Streaming responses
   - Typing indicators

2. **Advanced Concept Mapping**
   - NLP-based extraction
   - Semantic similarity
   - Knowledge graph integration

3. **Team Collaboration**
   - Shared workspaces
   - Permission management
   - Conversation forking

4. **Response Evaluation**
   - User ratings
   - Automated quality metrics
   - Feedback loops

5. **Knowledge Integration**
   - RAG (Retrieval-Augmented Generation)
   - Document upload
   - Web search integration
